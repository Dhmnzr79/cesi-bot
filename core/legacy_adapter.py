# core/legacy_adapter.py
"""
–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º.
–ü–æ–∑–≤–æ–ª—è–µ—Ç –ø–ª–∞–≤–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –æ—Ç —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –∫ –Ω–æ–≤–æ–º—É.
"""

from typing import Dict, Any, Tuple, List, Optional
from .answer_builder import build_json, to_legacy_text, LOW_REL_JSON
from .guard import should_use_guard_response
from .normalize import normalize_query_for_search
from .followups import followups_from_frontmatter
from .md_loader import parse_frontmatter, extract_cta_from_frontmatter, extract_meta_from_frontmatter


def safe_followups(fm: Dict[str, Any], md_body: str) -> List[Dict[str, Any]]:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ followups –±–µ–∑ –ø–∞–¥–µ–Ω–∏–π.
    """
    try:
        base = followups_from_frontmatter(fm)
    except Exception:
        base = []
    
    try:
        from .followups_enhanced import get_smart_followups
        smart = get_smart_followups(md_body, fm)
    except Exception:
        smart = []
    
    return (base or smart)[:3]


def _json_safe_meta(meta: Dict[str, Any]) -> Dict[str, Any]:
    """
    –î–µ–ª–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏.
    """
    meta = dict(meta or {})
    for k, v in meta.items():
        if isinstance(v, set):
            meta[k] = list(v)
    return meta
from config.feature_flags import feature_flags


def process_query_with_new_system(
    user_query: str,
    relevant_chunks: list,
    rag_meta: Dict[str, Any],
    candidates_with_scores: List[tuple] = None,
    payload: Optional[dict | str] = None,  # + –¥–æ–±–∞–≤–∏–ª–∏
) -> Tuple[str, Dict[str, Any]]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã.
    
    Args:
        user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        relevant_chunks: –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
        rag_meta: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç RAG —Å–∏—Å—Ç–µ–º—ã
        candidates_with_scores: –ö–∞–Ω–¥–∏–¥–∞—Ç—ã —Å–æ —Å–∫–æ—Ä—Ä–∞–º–∏ –¥–ª—è guard –ø—Ä–æ–≤–µ—Ä–∫–∏
    
    Returns:
        Tuple[response_text, response_metadata]
    """
    
    # –ü–µ—Ä–µ–¥ postprocessing - –¥–æ—Å—Ç–∞—ë–º/–Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º payload
    if payload is None:
        payload = rag_meta.get("response")  # –º—ã –∫–ª–∞–¥—ë–º –µ–≥–æ –≤—ã—à–µ –≤ adapt_rag_response
    if not isinstance(payload, dict):
        payload = {"text": (str(payload) if payload is not None else "")}
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
    if feature_flags.is_enabled("ENABLE_NORMALIZATION"):
        normalized_query = normalize_query_for_search(user_query)
    else:
        normalized_query = user_query
    
    # Guard –ø—Ä–æ–≤–µ—Ä–∫–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
    if feature_flags.is_enabled("ENABLE_GUARD"):
        from .guard import guard_with_candidates
        
        # –õ–æ–≥–∏—Ä—É–µ–º meta –¥–æ guard –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        print(f"üîç legacy_adapter: rag_meta.keys()={list(rag_meta.keys())}")
        print(f"üîç legacy_adapter: len(candidates_with_scores)={len(candidates_with_scores)}")
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –ª–æ–≥ –ø–µ—Ä–µ–¥ guard
        import logging
        logger = logging.getLogger("cesi.legacy_adapter")
        logger.info({
            "ev": "pre-guard",
            "cand_cnt": len(rag_meta.get("candidates_with_scores") or []),
            "rel": rag_meta.get("relevance_score") or (rag_meta.get("meta") or {}).get("relevance_score"),
        })
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç—ã —Å–æ —Å–∫–æ—Ä—Ä–∞–º–∏ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        if candidates_with_scores:
            should_use_guard, guard_response, extracted_scores = guard_with_candidates(
                candidates_with_scores,
                feature_flags.get("GUARD_THRESHOLD", 0.35),
                rag_meta
            )
        else:
            # Fallback –∫ —Å—Ç–∞—Ä—ã–º —Å–∫–æ—Ä—Ä–∞–º –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            scores = {
                "bm25_top1": rag_meta.get("bm25_score", 0.0),
                "dense_top1": rag_meta.get("dense_score", 0.0),
                "rerank_top1": rag_meta.get("rerank_score", 0.0)
            }
            
            # –ë–∞–π–ø–∞—Å: –µ—Å–ª–∏ –µ—Å—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç—ã - guard –Ω–µ –Ω—É–∂–µ–Ω
            cands = rag_meta.get("candidates_with_scores") or []
            if len(cands) > 0:
                should_use_guard, guard_response = False, None
            else:
                should_use_guard, guard_response = should_use_guard_response(
                    scores, 
                    feature_flags.get("GUARD_THRESHOLD", 0.35),
                    rag_meta
                )
            
            # –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –Ω–∏–∂–Ω–∏–π —Å–ª–æ–π –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç
            if isinstance(guard_response, tuple) and len(guard_response) == 2:
                payload, meta = guard_response
                if isinstance(payload, dict):
                    payload.setdefault("meta", {})
                    payload["meta"].update(meta or {})
                guard_response = payload
            
            extracted_scores = scores
        
        if should_use_guard:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º guard-–æ—Ç–≤–µ—Ç
            if feature_flags.is_json_mode():
                return None, guard_response
            else:
                legacy_text = to_legacy_text(guard_response)
                return legacy_text, {
                    "guard_used": True, 
                    "relevance_score": extracted_scores.get("max_score", 0.0),
                    "guard_threshold": feature_flags.get("GUARD_THRESHOLD", 0.35)
                }
    
    # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    if not relevant_chunks:
        # –ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        if feature_flags.is_json_mode():
            return None, LOW_REL_JSON
        else:
            legacy_text = to_legacy_text(LOW_REL_JSON)
            return legacy_text, {"no_chunks": True}
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞
    primary_chunk = relevant_chunks[0]
    
    # –ü–∞—Ä—Å–∏–º frontmatter –µ—Å–ª–∏ –µ—Å—Ç—å
    frontmatter = {}
    if hasattr(primary_chunk, 'metadata') and primary_chunk.metadata:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º metadata –≤ dict
        frontmatter = {
            "doc_type": getattr(primary_chunk.metadata, 'doc_type', 'info'),
            "topic": getattr(primary_chunk.metadata, 'topic', ''),
            "title": getattr(primary_chunk.metadata, 'title', ''),
            "cta_text": getattr(primary_chunk.metadata, 'cta_text', ''),
            "cta_link": getattr(primary_chunk.metadata, 'cta_link', ''),
            "tone": getattr(primary_chunk.metadata, 'tone', 'friendly'),
            "emotion": getattr(primary_chunk.metadata, 'emotion', ''),
            "verbatim": getattr(primary_chunk.metadata, 'verbatim', False)
        }
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º CTA
    cta_text, cta_link = extract_cta_from_frontmatter(frontmatter)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º followups (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã)
    followups = []
    if feature_flags.is_enabled("ENABLE_FOLLOWUPS"):
        from .followups_enhanced import get_smart_followups
        from .followups import filter_followups
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ followups
        content = ""
        if hasattr(primary_chunk, 'text'):
            content = primary_chunk.text
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ followups
        followups = safe_followups(frontmatter, content)
        
        # 3) –£–±—Ä–∞—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ —Ç–µ–∫—É—â–∏–π —Ä–∞–∑–¥–µ–ª (–µ—Å–ª–∏ —ç—Ç–æ –æ—Ç–≤–µ—Ç –ø–æ –¥–æ–ø-H2)
        current_h2_id = None
        if hasattr(primary_chunk, 'metadata') and primary_chunk.metadata:
            current_h2_id = getattr(primary_chunk.metadata, 'h2_id', None)
        
        followups = filter_followups(followups, current_h2_id, limit=3)
    
    # Post-processing –ø–µ—Ä–µ–¥ —Å–±–æ—Ä–∫–æ–π JSON
    from .postprocessing import clean_response_text, strip_textual_cta, clamp_text
    
    # –û—á–∏—â–∞–µ–º short –∏ bullets
    # –±—ã–ª–æ (–ø–æ —Å—Ç–µ–∫-—Ç—Ä–µ–π—Å—É —Ç–∞–∫ –∏ –ø–∞–¥–∞–ª–æ): 
    # short = clean_response_text(rag_meta.get("response", ""))
    # —Å—Ç–∞–ª–æ:
    text = ( (payload.get("text") if isinstance(payload, dict) else None) 
             or rag_meta.get("best_text")  # –º—ã –∫–ª–∞–¥—ë–º –µ–≥–æ –≤ rag_engine
             or "" )
    short = clean_response_text(text)
    short = clamp_text(short)
    bullets = [clean_response_text(b) for b in rag_meta.get("bullets", [])]
    
    # –£–¥–∞–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ CTA –µ—Å–ª–∏ –µ—Å—Ç—å UI CTA
    if cta_text and cta_link:
        short = strip_textual_cta(short, cta_text)
    
    # –°—Ç—Ä–æ–∏–º JSON –æ—Ç–≤–µ—Ç
    meta = _json_safe_meta(extract_meta_from_frontmatter(frontmatter))
    meta["followups_position"] = "above_cta"  # –ø–æ–¥—Å–∫–∞–∑–∫–∞ —Ñ—Ä–æ–Ω—Ç—É –ø—Ä–æ –ø–æ—Ä—è–¥–æ–∫
    
    # —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –≤–∏–¥–∂–µ—Ç–∞
    final_text = short or text
    payload["text"] = final_text
    
    json_response = build_json(
        short=short,
        bullets=bullets,
        cta_text=cta_text,
        cta_link=cta_link,
        followups=followups,
        used_chunks=rag_meta.get("used_chunks", []),
        meta=meta,
        warnings=rag_meta.get("warnings", [])
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º final_text –¥–ª—è –≤–∏–¥–∂–µ—Ç–∞
    json_response["response_mode"] = "json"  # ‚Üê –ò–°–ü–†–ê–í–õ–ï–ù–û
    json_response["final_text"] = final_text
    json_response["text"] = final_text  # ‚Üê –í–ê–ñ–ù–û: –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—Ä–æ–Ω—Ç—ã —á–∏—Ç–∞—é—Ç text
    json_response["low_relevance"] = False  # + –Ω–∞ –±—ç–∫—É —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä—ã–º —Ñ—Ä–æ–Ω—Ç–æ–º
    json_response["has_ui_cta"] = bool(payload.get("cta"))  # + —á—Ç–æ–±—ã —Ñ—Ä–æ–Ω—Ç –Ω–µ –¥—É–º–∞–ª, —á—Ç–æ —ç—Ç–æ —Ñ–æ–ª–±—ç–∫
    json_response["cta"] = payload.get("cta") or {}
    
    # –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–π –ª–æ–≥
    import logging
    logger = logging.getLogger("cesi.legacy_adapter")
    logger.info({"ev":"finalize", "final_text_len": len(final_text), "has_cta": bool(payload.get("cta"))})
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
    if feature_flags.is_enabled("POSTPROCESS_STRIP_TEXTUAL_CTA"):
        from .postprocessing import validate_response_structure
        json_response = validate_response_structure(json_response)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    if feature_flags.is_json_mode():
        return None, json_response
    else:
        # –í legacy —Ä–µ–∂–∏–º–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ short + bullets, –±–µ–∑ CTA/followups
        legacy_text = to_legacy_text(json_response)
        return legacy_text, {
            "json_converted": True,
            "legacy_mode": True,
            "cta_separated": bool(cta_text and cta_link),
            "followups_separated": len(followups) > 0
        }


def adapt_rag_response(
    user_query: str,
    rag_response: str,
    rag_meta: Dict[str, Any],
    relevant_chunks: list = None
) -> Tuple[str, Dict[str, Any]]:
    """
    –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç RAG —Å–∏—Å—Ç–µ–º—ã –∫ –Ω–æ–≤–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É.
    
    Args:
        user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        rag_response: –û—Ç–≤–µ—Ç –æ—Ç RAG —Å–∏—Å—Ç–µ–º—ã
        rag_meta: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç RAG
        relevant_chunks: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
    
    Returns:
        Tuple[response_text, response_metadata]
    """
    
    # –ï—Å–ª–∏ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if feature_flags.is_legacy_mode() and not any([
        feature_flags.is_enabled("ENABLE_FOLLOWUPS"),
        feature_flags.is_enabled("ENABLE_EMPATHY"),
        feature_flags.is_enabled("ENABLE_GUARD")
    ]):
        return rag_response, rag_meta
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É
    return process_query_with_new_system(
        user_query, 
        relevant_chunks or [], 
        {**rag_meta, "response": rag_response},
        rag_meta.get("candidates_with_scores", [])
    )
